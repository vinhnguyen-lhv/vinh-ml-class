{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Information Gain for Splitting on CreditScore at 650\n",
    "\n",
    "In this notebook, we calculate the information gain obtained by splitting the training dataset on the feature `CreditScore` at the threshold of 650. The dataset contains 8 records with two risk classes: **Low** and **High** (4 records each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c3d78-8476-4bd4-aee1-9b357cd31682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def entropy(labels):\n",
    "    \"\"\"Compute the entropy of a list of labels.\"\"\"\n",
    "    # Get unique classes and their counts\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Create the training dataset\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Age': [35, 28, 45, 31, 52, 29, 42, 33],\n",
    "    'CreditScore': [720, 650, 750, 600, 780, 630, 710, 640],\n",
    "    'Education': [16, 14, None, 12, 18, 14, 16, 12],\n",
    "    'RiskLevel': ['Low', 'High', 'Low', 'High', 'Low', 'High', 'Low', 'High']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the entropy of the parent node\n",
    "parent_entropy = entropy(df['RiskLevel'])\n",
    "print(\"Parent Entropy:\", parent_entropy)  \n",
    "\n",
    "# Split the dataset based on CreditScore at 650\n",
    "group_A = df[df['CreditScore'] >= 650]  # Group A: CreditScore >= 650\n",
    "group_B = df[df['CreditScore'] < 650]   # Group B: CreditScore < 650\n",
    "\n",
    "entropy_A = entropy(group_A['RiskLevel'])\n",
    "entropy_B = entropy(group_B['RiskLevel'])\n",
    "\n",
    "print(\"Entropy of Group A (CreditScore >= 650):\", entropy_A)\n",
    "print(\"Entropy of Group B (CreditScore < 650):\", entropy_B)\n",
    "\n",
    "# Calculate the weighted entropy after the split\n",
    "n = len(df)\n",
    "weighted_entropy = (len(group_A) / n) * entropy_A + (len(group_B) / n) * entropy_B\n",
    "print(\"Weighted Entropy after split:\", weighted_entropy)\n",
    "\n",
    "# Information Gain calculation\n",
    "information_gain = parent_entropy - weighted_entropy\n",
    "print(\"Information Gain:\", information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "1. **Parent Entropy:**\n",
    "   \n",
    "   Since the dataset is perfectly balanced with 4 **Low** and 4 **High** risk records, the entropy is calculated as:\n",
    "   \\[\n",
    "   E(\\text{parent}) = -\\left(\\frac{1}{2}\\log_2\\frac{1}{2} + \\frac{1}{2}\\log_2\\frac{1}{2}\\right) = 1 \\; \\text{bit}\n",
    "\n",
    "2. **Split Details:**\n",
    "   \n",
    "   - **Group A (CreditScore â‰¥ 650):** Contains 5 records (4 Low, 1 High).\n",
    "   - **Group B (CreditScore < 650):** Contains 3 records (all High).\n",
    "\n",
    "3. **Entropy After the Split:**\n",
    "   \n",
    "   The entropy of Group A and Group B is calculated separately and then weighted by the proportion of records in each group.\n",
    "\n",
    "4. **Information Gain:**\n",
    "   \n",
    "   The information gain is the reduction in entropy after the split:\n",
    "   \\[\n",
    "   \\text{Gain} = E(\\text{parent}) - E_{\\text{split}}\n",
    "   \\]\n",
    "\n",
    "   This value indicates how effective the split is at reducing uncertainty about the risk classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

